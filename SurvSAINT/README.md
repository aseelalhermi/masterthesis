# SurvSAINT ğŸ§ ğŸ“Š  
*A Self-Attention and Intersample Attention Transformer for Survival Analysis*

**SurvSAINT** is a robust transformer-based survival modeling framework that extends SAINT with support for:
- Classical Cox-based survival loss
- DeepHit loss (discrete-time modeling)
- Time-aware embeddings (via learnable or sinusoidal time encodings)
- Pretraining strategies and tabular augmentations

---

## ğŸ”§ Key Features

- âœ… **SAINT-style Attention**: Supports `colrow`, `row`, and `col` attention styles.
- â±ï¸ **Survival Losses**: Cox Proportional Hazards and DeepHit
- ğŸ§ª **Pretraining**: Self-supervised objectives for tabular feature recovery
- âŒ› **Time Embeddings**: For modeling time-aware representations (for `--task time`)
- ğŸ§© **Augmentations**: CutMix, MixUp, and other augmentations for tabular data
- ğŸ” **Optuna** hyperparameter tuning
- ğŸ§  **WandB Logging**: Full integration for tracking metrics and attention

---

## ğŸ“ Directory Structure

```

survsaint/
â”œâ”€â”€ augmentations.py           # MixUp, CutMix, Noise-based augmentations
â”œâ”€â”€ datasets.py                # Dataset loading and formatting
â”œâ”€â”€ losses.py                  # Cox, DeepHit, and contrastive losses
â”œâ”€â”€ pretraining.py             # Pretraining objectives
â”œâ”€â”€ data_openml.py             # OpenML integration and data cleaning
â”œâ”€â”€ utils.py                   # Helper utilities and config handlers
â”œâ”€â”€ train_survsaint.py         # ğŸ” CLI: main training and Optuna entrypoint
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ **init**.py
â”‚   â”œâ”€â”€ model.py               # Main SAINT architecture
â”‚   â”œâ”€â”€ timemodel.py           # SurvSAINT with time-aware embeddings
â”‚   â”œâ”€â”€ pretrainmodel.py       # Encoder for tabular pretraining
â”‚   â”œâ”€â”€ pretrainmodel_vision.py # Optional vision encoder (if present)

````

---

## ğŸš€ Getting Started

### 1. Install dependencies

```bash
pip install -r requirements.txt
````

---

## âš™ï¸ Training Commands

### â–¶ï¸ SurvSAINT (Standard Survival)

```bash
python train_survsaint.py \
  --survival \
  --active_log \
  --task survival \
  --optuna \
  --pretrain \
  --dataset metabric \
  --attentiontype colrow
```

### â–¶ï¸ SurvSAINT with DeepHit

```bash
python train_survsaint.py \
  --survival \
  --active_log \
  --task deephit \
  --optuna \
  --pretrain \
  --dataset metabric \
  --attentiontype colrow
```

### â–¶ï¸ SurvSAINT with Time Embeddings

```bash
python train_survsaint.py \
  --survival \
  --active_log \
  --task time \
  --optuna \
  --pretrain \
  --dataset metabric \
  --attentiontype colrow \
  --time_embedding_type learnable
```

---

## ğŸ§  Arguments (Key)

| Argument                | Description                                        |
| ----------------------- | -------------------------------------------------- |
| `--survival`            | Enable survival loss modeling                      |
| `--task`                | Choose from `survival`, `deephit`, or `time`       |
| `--optuna`              | Enable Optuna for hyperparameter tuning            |
| `--pretrain`            | Use self-supervised pretraining                    |
| `--attentiontype`       | Attention style: `colrow`, `row`, `col`            |
| `--dataset`             | Choose from `metabric`, `support`, `gbsg`, etc.    |
| `--time_embedding_type` | For `--task time`: use `learnable` or `sinusoidal` |
| `--active_log`          | Enable Weights & Biases logging                    |

---

## ğŸ“‰ Evaluation Metrics

* **C-Index**
* **Integrated Brier Score (IBS)**
* **Time-dependent Concordance**
* **Time-dependent AUC**
* **Calibration & Survival Curves**

Visual outputs and metrics are logged to [wandb.ai](https://wandb.ai).

---

## ğŸ§ª Pretraining Objectives

Supports masked feature prediction, contrastive learning, and mixup-style denoising strategies prior to survival fine-tuning.

To disable pretraining, simply omit the `--pretrain` flag.

---

## ğŸ“Š Example Results (from CLI)

SurvSAINT outputs after each seed run (aggregated across Optuna tuning), including:

* Evaluation Metrics

---

## ğŸª„ Example Dataset Support

* `metabric`
* `support`
* `gbsg`
* `flchain`
---


## ğŸ™‹ Contact

For issues, questions, or ideas, feel free to open a GitHub issue or discussion.



## Acknowledgements

We would like to thank the following public repo from which we borrowed various utilites.
- https://github.com/lucidrains/tab-transformer-pytorch
- https://github.com/somepago/saint/tree/main

## **License**
This repository is released under the Apache 2.0 license as found in the [LICENSE](LICENSE) file.




